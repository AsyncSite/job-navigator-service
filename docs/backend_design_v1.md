# Job Navigator ë°±ì—”ë“œ ì„¤ê³„ ë¬¸ì„œ v1.2 (êµ¬í˜„ ì™„ë£Œ)

## 1. ê°œìš”

### 1.1 ì„œë¹„ìŠ¤ëª…
**Job Navigator** - AsyncSiteì˜ ê°œë°œì ì±„ìš© ê³µê³  ìˆ˜ì§‘ ë° ë§¤ì¹­ ì„œë¹„ìŠ¤

> ì—…ë°ì´íŠ¸: 2025-08-01 - v1 êµ¬í˜„ ì™„ë£Œ, ëª¨ë“  ì´ìŠˆ í•´ê²°, í¬ë¡¤ëŸ¬ ì„œë¹„ìŠ¤ ì¤€ë¹„ ì™„ë£Œ

### 1.2 ì„¤ê³„ ì›ì¹™
- **ë‹¨ìˆœì„± ìš°ì„ **: v1ì€ MVPë¡œ í•µì‹¬ ê¸°ëŠ¥ì—ë§Œ ì§‘ì¤‘
- **ì•ˆì •ì„± ì¤‘ì‹œ**: í¬ë¡¤ë§ ì‹¤íŒ¨ì— ëŒ€í•œ ê²¬ê³ í•œ ì²˜ë¦¬
- **í™•ì¥ ê°€ëŠ¥ì„±**: í–¥í›„ ê¸°ëŠ¥ ì¶”ê°€ë¥¼ ê³ ë ¤í•œ êµ¬ì¡° ì„¤ê³„
- **AsyncSite í‘œì¤€ ì¤€ìˆ˜**: ê¸°ì¡´ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ ë° ì½”ë”© ê·œì¹™ ì¤€ìˆ˜

### 1.3 v1 ë²”ìœ„ (êµ¬í˜„ ìƒíƒœ)
- âœ… ~~íƒ€ê²Ÿ ê¸°ì—…(ë„¤ì¹´ë¼ì¿ ë°°) ì±„ìš© ê³µê³  í¬ë¡¤ë§~~ â†’ ìˆ˜ë™ ë°ì´í„° ì…ë ¥ìœ¼ë¡œ ëŒ€ì²´
- âœ… ê³µê³  ë°ì´í„° ì €ì¥ ë° ê´€ë¦¬ (ì™„ë£Œ)
- âœ… ê¸°ë³¸ ê²€ìƒ‰/í•„í„°ë§ API (ì™„ë£Œ)
- âœ… ê°„ë‹¨í•œ ê¸°ìˆ  ìŠ¤íƒ ë§¤ì¹­ (ì™„ë£Œ)
- âœ… Redis ìºì‹± (ì™„ë£Œ - 68% ì„±ëŠ¥ ê°œì„ )
- âœ… Gateway í†µí˜¥ (ì™„ë£Œ)
- âœ… TechStack í•„í„°ë§ (ì™„ë£Œ)
- âœ… ìƒì„¸ë³´ê¸° ê¸°ëŠ¥ (ì™„ë£Œ)
- âœ… ì…ë ¥ê°’ ê²€ì¦ (ì™„ë£Œ)
- ğŸš€ í¬ë¡¤ëŸ¬ ì„œë¹„ìŠ¤ (ì¤€ë¹„ ì™„ë£Œ, êµ¬í˜„ ëŒ€ê¸°)
- âŒ AI/ML ê¸°ë°˜ ë¶„ì„ (v2)
- âŒ ë³µì¡í•œ ì¶”ì²œ ì‹œìŠ¤í…œ (v2)
- âŒ ì»¤ë®¤ë‹ˆí‹° ê¸°ëŠ¥ (v2)

## 2. ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### 2.1 ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ êµ¬ì„±

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        API Gateway                           â”‚
â”‚                    (asyncsite-gateway)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚                     â”‚
                â”‚ /api/jobs/**        â”‚ /api/auth/**
                â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Job Navigator Service    â”‚ â”‚   User Service     â”‚
â”‚  (job-navigator-service)  â”‚ â”‚   (ê¸°ì¡´)           â”‚
â”‚                           â”‚ â”‚                    â”‚
â”‚  - ê³µê³  CRUD              â”‚ â”‚   - ì¸ì¦/ì¸ê°€      â”‚
â”‚  - ê²€ìƒ‰/í•„í„°ë§            â”‚ â”‚   - ì‚¬ìš©ì í”„ë¡œí•„  â”‚
â”‚  - ê¸°ìˆ  ë§¤ì¹­              â”‚ â”‚                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Job Crawler Service      â”‚
â”‚  (job-crawler-service)    â”‚
â”‚                           â”‚
â”‚  - ìŠ¤ì¼€ì¤„ë§               â”‚
â”‚  - í¬ë¡¤ë§ ì‹¤í–‰            â”‚
â”‚  - ë°ì´í„° íŒŒì‹±            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Shared Infrastructure                 â”‚
â”‚  - MySQL (asyncsite-mysql)                        â”‚
â”‚  - Redis (asyncsite-redis)                        â”‚
â”‚  - Eureka (asyncsite-eureka)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 ì„œë¹„ìŠ¤ë³„ ì±…ì„

#### Job Navigator Service (ë©”ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§)
- ì±„ìš© ê³µê³  CRUD ì‘ì—…
- ê²€ìƒ‰ ë° í•„í„°ë§ ê¸°ëŠ¥
- ê¸°ìˆ  ìŠ¤íƒ ë§¤ì¹­ ë¡œì§
- ì‚¬ìš©ìë³„ ê´€ì‹¬ ê³µê³  ê´€ë¦¬
- REST API ì œê³µ

#### Job Crawler Service (í¬ë¡¤ë§ ì „ë‹´)
- ìŠ¤ì¼€ì¤„ ê¸°ë°˜ í¬ë¡¤ë§ ì‹¤í–‰
- íƒ€ê²Ÿ ì‚¬ì´íŠ¸ë³„ í¬ë¡¤ëŸ¬ ê´€ë¦¬
- HTML íŒŒì‹± ë° ë°ì´í„° ì¶”ì¶œ
- í¬ë¡¤ë§ ìƒíƒœ ëª¨ë‹ˆí„°ë§
- Job Navigator Serviceë¡œ ë°ì´í„° ì „ì†¡

## 3. ê¸°ìˆ  ìŠ¤íƒ

### 3.1 Job Navigator Service (game-serviceì™€ ë™ì¼)
- **Language**: Java 21
- **Framework**: Spring Boot 3.5.3
- **Build**: Gradle
- **Database**: MySQL 8.0
- **Cache**: Redis
- **API Docs**: SpringDoc OpenAPI 2.8.0 (Swagger)
- **Security**: Spring Security + JWT
- **Service Discovery**: Spring Cloud Netflix Eureka
- **Testing**: JUnit 5, RestAssured, Testcontainers

### 3.2 Job Crawler Service
- **Language**: Python 3.11+
- **Framework**: FastAPI
- **Crawler**: BeautifulSoup4 + httpx (async)
- **Scheduler**: APScheduler
- **Task Queue**: Redis Queue
- **Settings**: Pydantic Settings
- **Logging**: structlog
- **Testing**: pytest + pytest-asyncio

## 4. Clean Architecture ì ìš©

### 4.1 Job Navigator Service íŒ¨í‚¤ì§€ êµ¬ì¡° (Java)

```
com.asyncsite.jobnavigator/
â”œâ”€â”€ adapter/
â”‚   â”œâ”€â”€ in/
â”‚   â”‚   â””â”€â”€ web/
â”‚   â”‚       â”œâ”€â”€ JobWebAdapter.java
â”‚   â”‚       â”œâ”€â”€ SearchWebAdapter.java
â”‚   â”‚       â””â”€â”€ UserJobWebAdapter.java
â”‚   â””â”€â”€ out/
â”‚       â”œâ”€â”€ persistence/
â”‚       â”‚   â”œâ”€â”€ JobPersistenceAdapter.java
â”‚       â”‚   â”œâ”€â”€ entity/
â”‚       â”‚   â”‚   â”œâ”€â”€ JobJpaEntity.java
â”‚       â”‚   â”‚   â””â”€â”€ CompanyJpaEntity.java
â”‚       â”‚   â”œâ”€â”€ mapper/
â”‚       â”‚   â”‚   â””â”€â”€ JobMapper.java
â”‚       â”‚   â””â”€â”€ repository/
â”‚       â”‚       â””â”€â”€ JobRepository.java
â”‚       â””â”€â”€ client/
â”‚           â””â”€â”€ CrawlerServiceClient.java
â”œâ”€â”€ application/
â”‚   â”œâ”€â”€ port/
â”‚   â”‚   â”œâ”€â”€ in/
â”‚   â”‚   â”‚   â”œâ”€â”€ CreateJobUseCase.java
â”‚   â”‚   â”‚   â”œâ”€â”€ SearchJobUseCase.java
â”‚   â”‚   â”‚   â””â”€â”€ MatchJobUseCase.java
â”‚   â”‚   â””â”€â”€ out/
â”‚   â”‚       â”œâ”€â”€ LoadJobPort.java
â”‚   â”‚       â”œâ”€â”€ SaveJobPort.java
â”‚   â”‚       â””â”€â”€ NotifyCrawlerPort.java
â”‚   â”œâ”€â”€ service/
â”‚   â”‚   â”œâ”€â”€ JobService.java
â”‚   â”‚   â”œâ”€â”€ SearchService.java
â”‚   â”‚   â””â”€â”€ MatchingService.java
â”‚   â””â”€â”€ dto/
â”‚       â”œâ”€â”€ JobResponse.java
â”‚       â””â”€â”€ SearchRequest.java
â””â”€â”€ domain/
    â”œâ”€â”€ Job.java
    â”œâ”€â”€ Company.java
    â”œâ”€â”€ TechStack.java
    â””â”€â”€ JobMatcher.java
```

### 4.2 Job Crawler Service íŒ¨í‚¤ì§€ êµ¬ì¡° (Python)

```
job_crawler_service/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ adapter/
â”‚   â”‚   â”œâ”€â”€ inbound/
â”‚   â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ crawler_controller.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ health_controller.py
â”‚   â”‚   â”‚   â””â”€â”€ scheduler/
â”‚   â”‚   â”‚       â””â”€â”€ crawl_scheduler.py
â”‚   â”‚   â””â”€â”€ outbound/
â”‚   â”‚       â”œâ”€â”€ crawler/
â”‚   â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚       â”‚   â”œâ”€â”€ base_crawler.py
â”‚   â”‚       â”‚   â”œâ”€â”€ naver_crawler.py
â”‚   â”‚       â”‚   â”œâ”€â”€ kakao_crawler.py
â”‚   â”‚       â”‚   â””â”€â”€ parsers/
â”‚   â”‚       â”‚       â””â”€â”€ job_parser.py
â”‚   â”‚       â””â”€â”€ client/
â”‚   â”‚           â””â”€â”€ job_service_client.py
â”‚   â”œâ”€â”€ application/
â”‚   â”‚   â”œâ”€â”€ port/
â”‚   â”‚   â”‚   â”œâ”€â”€ inbound/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ crawl_use_case.py
â”‚   â”‚   â”‚   â””â”€â”€ outbound/
â”‚   â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚       â”œâ”€â”€ crawl_job_port.py
â”‚   â”‚   â”‚       â””â”€â”€ send_job_port.py
â”‚   â”‚   â”œâ”€â”€ service/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ crawl_service.py
â”‚   â”‚   â””â”€â”€ dto/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â””â”€â”€ job_dto.py
â”‚   â”œâ”€â”€ domain/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ job.py
â”‚   â”‚   â””â”€â”€ crawl_result.py
â”‚   â””â”€â”€ infrastructure/
â”‚       â”œâ”€â”€ config/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â””â”€â”€ settings.py
â”‚       â”œâ”€â”€ logging/
â”‚       â”‚   â””â”€â”€ logger.py
â”‚       â””â”€â”€ monitoring/
â”‚           â””â”€â”€ metrics.py
â”œâ”€â”€ tests/
â”œâ”€â”€ requirements.txt
â””â”€â”€ Dockerfile
```

## 5. ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„

### 5.1 ì£¼ìš” í…Œì´ë¸”

```sql
-- íšŒì‚¬ ì •ë³´
CREATE TABLE companies (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    name VARCHAR(100) NOT NULL UNIQUE,
    name_en VARCHAR(100),
    career_page_url VARCHAR(500),
    logo_url VARCHAR(500),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    INDEX idx_name (name)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

-- ì±„ìš© ê³µê³ 
CREATE TABLE job_postings (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    company_id BIGINT NOT NULL,
    title VARCHAR(300) NOT NULL,
    description TEXT,
    requirements TEXT,
    preferred TEXT,
    
    -- êµ¬ì¡°í™”ëœ ì •ë³´
    job_type VARCHAR(50),  -- FULLTIME, CONTRACT, INTERN
    experience_level VARCHAR(50), -- JUNIOR, SENIOR, ANY
    location VARCHAR(200),
    
    -- ë©”íƒ€ ì •ë³´
    source_url VARCHAR(1000) NOT NULL UNIQUE,
    posted_at TIMESTAMP,
    expires_at TIMESTAMP,
    is_active BOOLEAN DEFAULT TRUE,
    
    -- í¬ë¡¤ë§ ì •ë³´
    raw_html LONGTEXT,
    crawled_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    FOREIGN KEY (company_id) REFERENCES companies(id),
    INDEX idx_company (company_id),
    INDEX idx_active (is_active),
    INDEX idx_posted (posted_at DESC)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

-- ê¸°ìˆ  ìŠ¤íƒ
CREATE TABLE tech_stacks (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    name VARCHAR(50) NOT NULL UNIQUE,
    category VARCHAR(50), -- LANGUAGE, FRAMEWORK, DATABASE, TOOL
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

-- ê³µê³ -ê¸°ìˆ ìŠ¤íƒ ë§¤í•‘
CREATE TABLE job_tech_stacks (
    job_posting_id BIGINT NOT NULL,
    tech_stack_id BIGINT NOT NULL,
    is_required BOOLEAN DEFAULT FALSE,
    PRIMARY KEY (job_posting_id, tech_stack_id),
    FOREIGN KEY (job_posting_id) REFERENCES job_postings(id) ON DELETE CASCADE,
    FOREIGN KEY (tech_stack_id) REFERENCES tech_stacks(id)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

-- ì‚¬ìš©ì ê´€ì‹¬ ê³µê³ 
CREATE TABLE user_saved_jobs (
    user_id BIGINT NOT NULL,
    job_posting_id BIGINT NOT NULL,
    saved_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    PRIMARY KEY (user_id, job_posting_id),
    FOREIGN KEY (job_posting_id) REFERENCES job_postings(id) ON DELETE CASCADE,
    INDEX idx_user (user_id)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

-- í¬ë¡¤ë§ ë¡œê·¸
CREATE TABLE crawl_logs (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    company_id BIGINT NOT NULL,
    status VARCHAR(20) NOT NULL, -- SUCCESS, FAILED, PARTIAL
    jobs_found INT DEFAULT 0,
    jobs_created INT DEFAULT 0,
    jobs_updated INT DEFAULT 0,
    error_message TEXT,
    started_at TIMESTAMP,
    finished_at TIMESTAMP,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (company_id) REFERENCES companies(id),
    INDEX idx_company_status (company_id, status),
    INDEX idx_created (created_at DESC)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
```

## 6. API ì„¤ê³„

### 6.1 Job Navigator Service API

#### ê³µê³  ê´€ë ¨ API

```yaml
# ê³µê³  ëª©ë¡ ì¡°íšŒ
GET /api/jobs
Query Parameters:
  - page: int (default: 0)
  - size: int (default: 20)
  - company: string[] (optional)
  - tech: string[] (optional)
  - experience: string (optional)
  - keyword: string (optional)
Response:
  {
    "content": [...],
    "pageable": {...},
    "totalElements": 100
  }

# ê³µê³  ìƒì„¸ ì¡°íšŒ
GET /api/jobs/{id}
Response:
  {
    "id": 1,
    "company": {...},
    "title": "ë°±ì—”ë“œ ê°œë°œì",
    "techStacks": [...],
    ...
  }

# ê³µê³  ì €ì¥ (ê´€ì‹¬ í‘œì‹œ)
POST /api/jobs/{id}/save
Headers: Authorization: Bearer {token}
Response: 204 No Content

# ì €ì¥ëœ ê³µê³  ëª©ë¡
GET /api/jobs/my/saved
Headers: Authorization: Bearer {token}
```

#### ê²€ìƒ‰/í•„í„° API

```yaml
# íšŒì‚¬ ëª©ë¡ (ìë™ì™„ì„±ìš©)
GET /api/jobs/companies
Query Parameters:
  - q: string (optional)

# ê¸°ìˆ  ìŠ¤íƒ ëª©ë¡
GET /api/jobs/tech-stacks
Query Parameters:
  - category: string (optional)
```

### 6.2 Job Crawler Service API (ë‚´ë¶€ìš©)

```yaml
# í¬ë¡¤ë§ íŠ¸ë¦¬ê±° (ìˆ˜ë™)
POST /api/crawler/trigger
Body:
  {
    "company": "naver" // optional, ì „ì²´ ì‹¤í–‰ ì‹œ ìƒëµ
  }

# í¬ë¡¤ë§ ìƒíƒœ ì¡°íšŒ
GET /api/crawler/status

# í¬ë¡¤ë§ ë¡œê·¸ ì¡°íšŒ
GET /api/crawler/logs
Query Parameters:
  - days: int (default: 7)
```

## 7. í•µì‹¬ ì‹œí€€ìŠ¤ ë‹¤ì´ì–´ê·¸ë¨

### 7.1 í¬ë¡¤ë§ ì‹¤í–‰ í”Œë¡œìš°

```mermaid
sequenceDiagram
    participant S as Scheduler
    participant CS as CrawlService
    participant C as Crawler
    participant JC as JobServiceClient
    participant JS as JobNavigatorService
    participant DB as MySQL

    S->>CS: ë§¤ì¼ 3ì‹œ í¬ë¡¤ë§ ì‹œì‘
    CS->>CS: í¬ë¡¤ë§ ë¡œê·¸ ìƒì„±
    
    loop ê° íƒ€ê²Ÿ íšŒì‚¬ë³„
        CS->>C: í¬ë¡¤ëŸ¬ ì‹¤í–‰
        C->>C: fetch_job_list()
        C->>C: ê³µê³  ëª©ë¡ URL ìˆ˜ì§‘
        
        loop ê° ê³µê³ ë³„
            C->>C: parse_job_detail(url)
            Note over C: 1-2ì´ˆ ë”œë ˆì´
            C->>C: ê¸°ìˆ  ìŠ¤íƒ ì¶”ì¶œ
        end
        
        C-->>CS: í¬ë¡¤ë§ ê²°ê³¼ ë°˜í™˜
        CS->>JC: ê³µê³  ë°ì´í„° ì „ì†¡
        JC->>JS: POST /api/jobs/batch
        JS->>DB: ì¤‘ë³µ ì²´í¬ (source_url)
        
        alt ì‹ ê·œ ê³µê³ 
            JS->>DB: INSERT job_postings
        else ê¸°ì¡´ ê³µê³ 
            JS->>DB: UPDATE job_postings
        end
        
        JS-->>JC: ì²˜ë¦¬ ê²°ê³¼
        JC-->>CS: ì‘ë‹µ
    end
    
    CS->>CS: í¬ë¡¤ë§ ë¡œê·¸ ì—…ë°ì´íŠ¸
    CS->>DB: UPDATE crawl_logs
```

### 7.2 ì‚¬ìš©ì ê³µê³  ì¡°íšŒ í”Œë¡œìš°

```mermaid
sequenceDiagram
    participant U as User
    participant GW as API Gateway
    participant JS as JobNavigatorService
    participant R as Redis
    participant DB as MySQL

    U->>GW: GET /api/jobs?tech=Java,Spring
    GW->>JS: ìš”ì²­ ì „ë‹¬ (JWT ê²€ì¦ë¨)
    
    JS->>R: ìºì‹œ ì¡°íšŒ (careers:jobs:list:Java,Spring)
    
    alt ìºì‹œ íˆíŠ¸
        R-->>JS: ìºì‹œëœ ê²°ê³¼
    else ìºì‹œ ë¯¸ìŠ¤
        JS->>DB: SELECT FROM job_postings
        Note over DB: JOIN companies, tech_stacks
        DB-->>JS: ê³µê³  ëª©ë¡
        JS->>R: ìºì‹œ ì €ì¥ (TTL 5ë¶„)
    end
    
    JS-->>GW: ê³µê³  ëª©ë¡ ì‘ë‹µ
    GW-->>U: ê²°ê³¼ í‘œì‹œ
```

### 7.3 ê³µê³  ì €ì¥/ê´€ì‹¬ í‘œì‹œ í”Œë¡œìš°

```mermaid
sequenceDiagram
    participant U as User
    participant GW as API Gateway
    participant JS as JobNavigatorService
    participant US as UserService
    participant DB as MySQL

    U->>GW: POST /api/jobs/123/save
    Note over GW: Authorization: Bearer {token}
    
    GW->>JS: ìš”ì²­ ì „ë‹¬ (user_id í¬í•¨)
    JS->>DB: ê³µê³  ì¡´ì¬ í™•ì¸
    
    alt ê³µê³  ì¡´ì¬
        JS->>US: ì‚¬ìš©ì ê²€ì¦ (Optional)
        US-->>JS: ì‚¬ìš©ì ì •ë³´
        
        JS->>DB: INSERT INTO user_saved_jobs
        Note over DB: ON DUPLICATE KEY IGNORE
        
        DB-->>JS: ì €ì¥ ì™„ë£Œ
        JS-->>GW: 204 No Content
    else ê³µê³  ì—†ìŒ
        JS-->>GW: 404 Not Found
    end
    
    GW-->>U: ì‘ë‹µ
```

### 7.4 ê¸°ìˆ  ë§¤ì¹­ í”Œë¡œìš°

```mermaid
sequenceDiagram
    participant U as User
    participant JS as JobNavigatorService
    participant MS as MatchingService
    participant DB as MySQL

    U->>JS: GET /api/jobs/123/match
    Note over JS: ì‚¬ìš©ì í”„ë¡œí•„ í•„ìš”
    
    JS->>DB: ê³µê³  ê¸°ìˆ  ìŠ¤íƒ ì¡°íšŒ
    DB-->>JS: required_skills, preferred_skills
    
    JS->>MS: ë§¤ì¹­ ìš”ì²­
    MS->>MS: ì‚¬ìš©ì ê¸°ìˆ  vs ê³µê³  ìš”êµ¬ì‚¬í•­
    
    Note over MS: ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜<br/>1. í•„ìˆ˜ ê¸°ìˆ  ë³´ìœ ìœ¨<br/>2. ìš°ëŒ€ ê¸°ìˆ  ë³´ìœ ìœ¨<br/>3. ê°€ì¤‘ í‰ê·  ê³„ì‚°
    
    MS-->>JS: ë§¤ì¹­ ê²°ê³¼
    JS-->>U: {<br/>  "matchRate": 75,<br/>  "missingSkills": ["Kafka", "Docker"]<br/>}
```

### 7.5 í¬ë¡¤ë§ ì‹¤íŒ¨ ì²˜ë¦¬ í”Œë¡œìš°

```mermaid
sequenceDiagram
    participant S as Scheduler
    participant CS as CrawlService
    participant C as Crawler
    participant N as NotificationService
    participant DB as MySQL

    S->>CS: í¬ë¡¤ë§ ì‹œì‘
    CS->>C: ë„¤ì´ë²„ í¬ë¡¤ëŸ¬ ì‹¤í–‰
    
    alt ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜
        C--xCS: ConnectionError
        CS->>CS: ì¬ì‹œë„ ì¹´ìš´í„° ì¦ê°€
        
        loop ìµœëŒ€ 3íšŒ
            CS->>C: ì¬ì‹œë„ (30ë¶„ í›„)
            
            alt ì„±ê³µ
                C-->>CS: í¬ë¡¤ë§ ê²°ê³¼
                CS->>DB: ì •ìƒ ì²˜ë¦¬
            else ê³„ì† ì‹¤íŒ¨
                C--xCS: Error
            end
        end
        
        CS->>DB: ì‹¤íŒ¨ ë¡œê·¸ ê¸°ë¡
        CS->>N: ì•Œë¦¼ ë°œì†¡
        N->>N: Slack/Email ì „ì†¡
        
    else íŒŒì‹± ì˜¤ë¥˜ (êµ¬ì¡° ë³€ê²½)
        C-->>CS: ParsingError
        CS->>DB: ì‹¤íŒ¨ ë¡œê·¸ (ìƒì„¸ ì˜¤ë¥˜)
        CS->>N: ê¸´ê¸‰ ì•Œë¦¼
        Note over N: "ë„¤ì´ë²„ ì‚¬ì´íŠ¸ êµ¬ì¡° ë³€ê²½ ê°ì§€"
    end
```

## 8. í¬ë¡¤ë§ ì „ëµ

### 8.1 íƒ€ê²Ÿ ê¸°ì—… (v1)
1. ë„¤ì´ë²„ (careers.naver.com)
2. ì¹´ì¹´ì˜¤ (careers.kakao.com)
3. ë¼ì¸ (careers.linecorp.com)
4. ì¿ íŒ¡ (coupang.jobs)
5. ë°°ë‹¬ì˜ë¯¼ì¡± (career.woowahan.com)

### 8.2 í¬ë¡¤ë§ ìŠ¤ì¼€ì¤„
- ë§¤ì¼ ìƒˆë²½ 3ì‹œ ì •ê¸° ì‹¤í–‰
- ì‹¤íŒ¨ ì‹œ 30ë¶„ í›„ ì¬ì‹œë„ (ìµœëŒ€ 3íšŒ)
- ìˆ˜ë™ íŠ¸ë¦¬ê±° ê°€ëŠ¥

### 8.3 Python í¬ë¡¤ëŸ¬ êµ¬í˜„ (Clean Architecture)

```python
# domain/job.py
from dataclasses import dataclass
from typing import List, Optional
from datetime import datetime

@dataclass
class Job:
    """ë„ë©”ì¸ ëª¨ë¸ - í”„ë ˆì„ì›Œí¬ ë…ë¦½ì """
    title: str
    company_name: str
    description: str
    requirements: str
    preferred: Optional[str]
    tech_stacks: List[str]
    job_type: str
    experience_level: str
    location: str
    source_url: str
    posted_at: Optional[datetime]
    expires_at: Optional[datetime]

# application/port/outbound/crawl_job_port.py
from abc import ABC, abstractmethod
from typing import List
from domain.job import Job

class CrawlJobPort(ABC):
    """í¬ë¡¤ë§ í¬íŠ¸ ì¸í„°í˜ì´ìŠ¤"""
    
    @abstractmethod
    async def fetch_job_list(self) -> List[str]:
        """ê³µê³  ëª©ë¡ URL ìˆ˜ì§‘"""
        pass
    
    @abstractmethod
    async def parse_job_detail(self, url: str) -> Job:
        """ê³µê³  ìƒì„¸ ì •ë³´ íŒŒì‹±"""
        pass

# adapter/outbound/crawler/base_crawler.py
import httpx
from bs4 import BeautifulSoup
from typing import Dict, List
import asyncio
import random
from application.port.outbound.crawl_job_port import CrawlJobPort
from infrastructure.logging.logger import get_logger

logger = get_logger(__name__)

class BaseCrawler(CrawlJobPort):
    """í¬ë¡¤ëŸ¬ ë² ì´ìŠ¤ í´ë˜ìŠ¤"""
    
    def __init__(self, company_name: str):
        self.company_name = company_name
        self.client = self._create_client()
        
    def _create_client(self) -> httpx.AsyncClient:
        return httpx.AsyncClient(
            headers={
                'User-Agent': 'Mozilla/5.0 (compatible; AsyncSite-JobBot/1.0)',
                'Accept-Language': 'ko-KR,ko;q=0.9,en;q=0.8'
            },
            timeout=30.0
        )
    
    async def crawl(self) -> List[Job]:
        """ë©”ì¸ í¬ë¡¤ë§ ë¡œì§"""
        jobs = []
        
        try:
            job_urls = await self.fetch_job_list()
            logger.info(f"Found {len(job_urls)} jobs from {self.company_name}")
            
            for url in job_urls:
                try:
                    # Rate limiting
                    await asyncio.sleep(random.uniform(1, 2))
                    
                    job = await self.parse_job_detail(url)
                    jobs.append(job)
                    
                except Exception as e:
                    logger.error(f"Failed to parse {url}: {e}")
                    continue
                    
        except Exception as e:
            logger.error(f"Failed to fetch job list from {self.company_name}: {e}")
            raise
        finally:
            await self.client.aclose()
            
        return jobs
```

### 8.4 ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„ ì „ëµ

```python
# infrastructure/resilience/retry.py
from typing import TypeVar, Callable, Any
import asyncio
from functools import wraps

T = TypeVar('T')

def retry_with_backoff(
    max_attempts: int = 3,
    backoff_factor: float = 2.0,
    exceptions: tuple = (Exception,)
):
    """ì§€ìˆ˜ ë°±ì˜¤í”„ ì¬ì‹œë„ ë°ì½”ë ˆì´í„°"""
    def decorator(func: Callable[..., T]) -> Callable[..., T]:
        @wraps(func)
        async def wrapper(*args, **kwargs) -> T:
            attempt = 0
            delay = 1.0
            
            while attempt < max_attempts:
                try:
                    return await func(*args, **kwargs)
                except exceptions as e:
                    attempt += 1
                    if attempt >= max_attempts:
                        raise
                    
                    await asyncio.sleep(delay)
                    delay *= backoff_factor
                    
        return wrapper
    return decorator
```

## 9. ìºì‹± ì „ëµ

### 9.1 Redis ìºì‹± (Java)
```java
@Component
public class CacheConfig {
    public static final String JOB_LIST_CACHE = "jobs:list";
    public static final String JOB_DETAIL_CACHE = "jobs:detail:";
    public static final String COMPANY_LIST_CACHE = "companies:all";
    public static final String TECH_STACKS_CACHE = "tech:all";
    
    public static final int JOB_LIST_TTL = 300; // 5ë¶„
    public static final int JOB_DETAIL_TTL = 3600; // 1ì‹œê°„
    public static final int COMPANY_LIST_TTL = 86400; // 1ì¼
    public static final int TECH_STACKS_TTL = 86400; // 1ì¼
}
```

## 10. ëª¨ë‹ˆí„°ë§ ë° ê´€ì°°ì„±

### 10.1 êµ¬ì¡°í™”ëœ ë¡œê¹…

```java
// Java (Job Navigator Service)
@Slf4j
public class JobService {
    public void processJobs(List<Job> jobs) {
        log.info("Processing jobs batch", 
            "company", jobs.get(0).getCompany().getName(),
            "count", jobs.size(),
            "timestamp", Instant.now()
        );
    }
}
```

```python
# Python (Job Crawler Service)
from infrastructure.logging.logger import get_logger

logger = get_logger(__name__)

async def crawl_company(company: str):
    logger.info("Starting crawl", 
        company=company,
        timestamp=datetime.utcnow().isoformat()
    )
```

### 10.2 ë©”íŠ¸ë¦­ ìˆ˜ì§‘

```python
# infrastructure/monitoring/metrics.py
from prometheus_client import Counter, Histogram, Gauge

# í¬ë¡¤ë§ ë©”íŠ¸ë¦­
crawl_jobs_total = Counter(
    'crawler_jobs_total',
    'Total number of jobs crawled',
    ['company', 'status']
)

crawl_duration = Histogram(
    'crawler_duration_seconds',
    'Time spent crawling',
    ['company']
)

active_crawlers = Gauge(
    'crawler_active_total',
    'Number of active crawlers'
)
```

## 11. ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

### 11.1 í¬ë¡¤ë§ ìœ¤ë¦¬
- robots.txt ì¤€ìˆ˜
- User-Agent ëª…ì‹œ
- ì ì ˆí•œ ë”œë ˆì´ ì„¤ì • (1-2ì´ˆ)
- ê³¼ë„í•œ ìš”ì²­ ë°©ì§€

### 11.2 ë°ì´í„° ë³´ì•ˆ
- ê°œì¸ì •ë³´ ìˆ˜ì§‘ ê¸ˆì§€
- ê³µê°œëœ ì •ë³´ë§Œ ìˆ˜ì§‘
- ì›ë³¸ ì¶œì²˜ ëª…ì‹œ

## 12. ë°°í¬ ì „ëµ

### 12.1 Docker êµ¬ì„±
```yaml
# docker-compose ì¶”ê°€ ì„œë¹„ìŠ¤
job-navigator-service:
  build: ./job-navigator-service
  container_name: asyncsite-job-navigator
  environment:
    - SPRING_PROFILES_ACTIVE=docker
    - EUREKA_CLIENT_SERVICE_URL_DEFAULTZONE=http://asyncsite-eureka:8761/eureka/
    - SPRING_DATASOURCE_URL=jdbc:mysql://asyncsite-mysql:3306/job_db
  depends_on:
    - mysql
    - eureka-server
    - redis

job-crawler-service:
  build: ./job-crawler-service
  container_name: asyncsite-job-crawler
  environment:
    - JOB_SERVICE_URL=http://job-navigator-service:8080
    - REDIS_URL=redis://asyncsite-redis:6379
    - ENVIRONMENT=production
  depends_on:
    - job-navigator-service
    - redis
```

## 13. í–¥í›„ í™•ì¥ ê³„íš (v2+)

### 13.1 ê¸°ëŠ¥ í™•ì¥
- AI ê¸°ë°˜ ê³µê³  ë¶„ì„
- ê°œì¸í™” ì¶”ì²œ ì‹œìŠ¤í…œ
- ì»¤ë®¤ë‹ˆí‹° ê¸°ëŠ¥ (ì‘ì „ íšŒì˜ì‹¤)
- ê¸°ì—… ë¬¸í™” ì ìˆ˜
- ì„±ì¥ ê°€ëŠ¥ì„± ë¶„ì„

### 13.2 ê¸°ìˆ  í™•ì¥
- Elasticsearch ë„ì… (ê³ ê¸‰ ê²€ìƒ‰)
- Kafka ë„ì… (ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë°)
- ë¨¸ì‹ ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸

## 14. ê°œë°œ ì¼ì • (ì˜ˆìƒ)

### Phase 1: ê¸°ë°˜ êµ¬ì¶• (2ì£¼)
- [ ] Job Navigator Service í”„ë¡œì íŠ¸ ìƒì„±
- [ ] ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ êµ¬í˜„
- [ ] ê¸°ë³¸ API êµ¬í˜„

### Phase 2: í¬ë¡¤ëŸ¬ ê°œë°œ (3ì£¼)
- [ ] í¬ë¡¤ëŸ¬ í”„ë ˆì„ì›Œí¬ êµ¬ì¶•
- [ ] íƒ€ê²Ÿ ê¸°ì—…ë³„ í¬ë¡¤ëŸ¬ êµ¬í˜„
- [ ] ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •

### Phase 3: í†µí•© ë° í…ŒìŠ¤íŠ¸ (2ì£¼)
- [ ] ì„œë¹„ìŠ¤ ê°„ í†µí•©
- [ ] í…ŒìŠ¤íŠ¸ ì‘ì„±
- [ ] ë²„ê·¸ ìˆ˜ì • ë° ì•ˆì •í™”

### Phase 4: ë°°í¬ (1ì£¼)
- [ ] Docker ì´ë¯¸ì§€ ë¹Œë“œ
- [ ] ìš´ì˜ í™˜ê²½ ë°°í¬
- [ ] ëª¨ë‹ˆí„°ë§ ì„¤ì •

ì´ ì˜ˆìƒ ê¸°ê°„: 8ì£¼

## 8. êµ¬í˜„ ì™„ë£Œ ì‚¬í•­ (2025-08-01)

### 8.1 êµ¬í˜„ëœ ê¸°ëŠ¥
- âœ… Clean Architecture ê¸°ë°˜ í”„ë¡œì íŠ¸ êµ¬ì¡°
- âœ… ì±„ìš©ê³µê³  CRUD API
- âœ… íšŒì‚¬ ê´€ë¦¬ API  
- âœ… ê¸°ìˆ  ìŠ¤íƒ ê´€ë¦¬ API
- âœ… ê²€ìƒ‰ ë° í•„í„°ë§ ê¸°ëŠ¥ (í‚¤ì›Œë“œ, íšŒì‚¬, ê²½ë ¥ ìˆ˜ì¤€, ê¸°ìˆ  ìŠ¤íƒ)
- âœ… Redis ìºì‹± (ì§ì ‘ í˜¸ì¶œ: 222ms â†’ 71ms, Gateway: 878ms â†’ 664ms)
- âœ… API Gateway í†µí•©
- âœ… Swagger UI ë¬¸ì„œí™”
- âœ… TechStack Many-to-Many ê´€ê³„ ë§¤í•‘
- âœ… í”„ë¡ íŠ¸ì—”ë“œ ì—°ë™ ì™„ë£Œ
- âœ… DataInitializerë¥¼ í†µí•œ ëª©ì—… ë°ì´í„° ìƒì„± (10ê°œ ì±„ìš©ê³µê³ , 15ê°œ íšŒì‚¬)
- âœ… ìƒì„¸ë³´ê¸° ê¸°ëŠ¥ (JobDetailModal)
- âœ… ìºì‹± ë¡œì§ ë²„ê·¸ ìˆ˜ì • (í•„í„°ë§ëœ ê²°ê³¼ ìºì‹œ)
- âœ… ì…ë ¥ê°’ ê²€ì¦ ì¶”ê°€
- âœ… CI/CD ë¹Œë“œ ì‹¤íŒ¨ í•´ê²°

### 8.2 ì£¼ìš” ê¸°ìˆ ì  ì´ìŠˆì™€ í•´ê²°

#### 1. Redis ì—­ì§ë ¬í™” ë¬¸ì œ
**ë¬¸ì œ**: `java.time.LocalDateTime` not supported by default ì˜¤ë¥˜

**í•´ê²°**: 
```java
// RedisConfig.java
@Bean(name = "redisObjectMapper")
public ObjectMapper redisObjectMapper() {
    ObjectMapper objectMapper = new ObjectMapper();
    objectMapper.registerModule(new JavaTimeModule()); // í•µì‹¬!
    objectMapper.activateDefaultTyping(
        objectMapper.getPolymorphicTypeValidator(),
        ObjectMapper.DefaultTyping.NON_FINAL
    );
    return objectMapper;
}

// Job.java
@JsonDeserialize(builder = Job.JobBuilder.class)
public class Job {
    @JsonPOJOBuilder(withPrefix = "")
    public static class JobBuilder { }
}
```

#### 2. TechStack ê´€ê³„ ë¡œë”© ë¬¸ì œ
**ë¬¸ì œ**: API ì‘ë‹µì—ì„œ skills ë°°ì—´ì´ ë¹„ì–´ìˆìŒ

**í•´ê²°**:
1. JobPersistenceAdapterì— TechStack ì €ì¥ ë¡œì§ ì¶”ê°€
```java
// í•„ìˆ˜ ê¸°ìˆ  ìŠ¤íƒ ì €ì¥
if (job.getRequiredTechStacks() != null) {
    for (TechStack techStack : job.getRequiredTechStacks()) {
        JobTechStackJpaEntity jobTechStack = JobTechStackJpaEntity.builder()
                .jobPosting(saved)
                .techStack(techStackEntity)
                .isRequired(true)
                .build();
        jobTechStackRepository.save(jobTechStack);
    }
}
```

2. Fetch Join ì¿¼ë¦¬ë¡œ Lazy Loading í•´ê²°
```java
@Query("SELECT DISTINCT j FROM JobPostingJpaEntity j " +
       "LEFT JOIN FETCH j.company c " +
       "LEFT JOIN FETCH j.jobTechStacks jts " +
       "LEFT JOIN FETCH jts.techStack ts " +
       "WHERE j.isActive = true")
List<JobPostingJpaEntity> findActiveJobsWithTechStacks();
```

#### 3. Gateway í†µí•© ë¬¸ì œ
**ë¬¸ì œ**: 401 Unauthorized ì˜¤ë¥˜

**í•´ê²°**: SecurityConfigì— ê³µê°œ ê²½ë¡œ ì¶”ê°€
```kotlin
PathPatternParserServerWebExchangeMatcher("/api/job-navigator/**"),
PathPatternParserServerWebExchangeMatcher("/api/job-navigator/swagger-ui.html"),
PathPatternParserServerWebExchangeMatcher("/api/job-navigator/swagger-ui/**"),
```

#### 4. Docker ë°°í¬ ìºì‹± ë¬¸ì œ
**ë¬¸ì œ**: ì½”ë“œ ë³€ê²½ì´ ë°˜ì˜ë˜ì§€ ì•ŠìŒ

**í•´ê²°**: Docker ì´ë¯¸ì§€ ì¬ë¹Œë“œ í•„ìˆ˜
```bash
# ë°˜ë“œì‹œ ì´ ìˆœì„œë¡œ ì‹¤í–‰
./gradlew clean build -x test
docker-compose -f docker-compose.job-navigator-only.yml build job-navigator-service
docker-compose -f docker-compose.job-navigator-only.yml up -d job-navigator-service
```

### 8.3 ì„±ëŠ¥ ì§€í‘œ (2025-08-01 ì—…ë°ì´íŠ¸)
- ì§ì ‘ ì„œë¹„ìŠ¤ í˜¸ì¶œ: 222ms â†’ 71ms (68% ê°œì„ )
- Gateway ê²½ìœ  í˜¸ì¶œ: 878ms â†’ 664ms (24% ê°œì„ )
- í‰ê·  ì‘ë‹µ ì‹œê°„: ~150ms
- ë™ì‹œ ìš”ì²­ ì²˜ë¦¬: í…ŒìŠ¤íŠ¸ í•„ìš”
- ìºì‹œ ì ì¤‘ë¥ : ë†’ìŒ (í•„í„°ë§ëœ ê²°ê³¼ ìºì‹±)

### 8.4 í˜„ì¬ ìƒíƒœ ë° ë‚¨ì€ ì‘ì—…

#### ì™„ë£Œëœ ì‘ì—…
- ëª¨ë“  í•µì‹¬ API êµ¬í˜„ ì™„ë£Œ
- í”„ë¡ íŠ¸ì—”ë“œ ì—°ë™ ì™„ë£Œ
- TechStack í•„í„°ë§ ë¡œì§ ì¶”ê°€ (í…ŒìŠ¤íŠ¸ í•„ìš”)

#### í•´ê²°ëœ ì´ìŠˆ
1. **ìºì‹± ë¡œì§ ë²„ê·¸** - í•„í„°ë§ëœ ê²°ê³¼ë¥¼ ìºì‹œí•˜ë„ë¡ ìˆ˜ì • ì™„ë£Œ
2. **ì…ë ¥ê°’ ê²€ì¦** - í˜ì´ì§€ ë²ˆí˜¸, í¬ê¸°, í‚¤ì›Œë“œ ê¸¸ì´ ê²€ì¦ ì™„ë£Œ
3. **TechStack í•„í„°ë§** - í…ŒìŠ¤íŠ¸ ì™„ë£Œ ë° ì •ìƒ ì‘ë™
4. **CI/CD ë¹Œë“œ ì‹¤íŒ¨** - ëˆ„ë½ëœ 31ê°œ íŒŒì¼ ëª¨ë‘ ì¶”ê°€

#### ë‹¤ìŒ ì‘ì—…
- **í¬ë¡¤ëŸ¬ ì„œë¹„ìŠ¤ êµ¬í˜„** - Python ê¸°ë°˜, Clean Architecture, ì„¤ê³„ ì™„ë£Œ
- í”„ë¡ íŠ¸ì—”ë“œ ê²€ìƒ‰ ë””ë°”ìš´ì‹±
- ì‚¬ìš©ìë³„ ê´€ì‹¬ ê³µê³  ì €ì¥ ê¸°ëŠ¥
- ë§¤ì¹­ ì ìˆ˜ ê³„ì‚° ë¡œì§

### 8.5 ì¤‘ìš” ê°œë°œ íŒ
1. **Docker ì¬ë¹Œë“œ í•„ìˆ˜**: ì½”ë“œ ë³€ê²½ ì‹œ ë°˜ë“œì‹œ ì´ë¯¸ì§€ ì¬ë¹Œë“œ
2. **Redis ìºì‹œ í™•ì¸**: í…ŒìŠ¤íŠ¸ ì‹œ ìºì‹œë¥¼ ë¹„ìš°ê³  ì‹œì‘
3. **ë¡œê·¸ ë ˆë²¨ ì¡°ì •**: ë””ë²„ê¹… ì‹œ DEBUG, ìš´ì˜ ì‹œ INFO
4. **DB ì§ì ‘ í™•ì¸**: JPA ë™ì‘ì´ ì˜ì‹¬ìŠ¤ëŸ¬ìš¸ ë•Œ MySQL ì§ì ‘ ì¿¼ë¦¬

---

**2025-08-01 í˜„ì¬ ìƒíƒœ**: 
- Job Navigator Serviceì˜ ëª¨ë“  í•µì‹¬ ê¸°ëŠ¥ì´ êµ¬í˜„ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.
- ì›¹ í”„ë¡ íŠ¸ì—”ë“œì™€ì˜ ì—°ë™ì´ ì™„ë²½í•˜ê²Œ ì‘ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤.
- ìºì‹±, í•„í„°ë§, ì…ë ¥ê°’ ê²€ì¦ ë“± ëª¨ë“  ì´ìŠˆê°€ í•´ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.
- í¬ë¡¤ëŸ¬ ì„œë¹„ìŠ¤ êµ¬í˜„ì„ ì‹œì‘í•  ì¤€ë¹„ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.

ì´ ì„¤ê³„ëŠ” AsyncSiteì˜ ê¸°ì¡´ ì•„í‚¤í…ì²˜ì™€ ì¼ê´€ì„±ì„ ìœ ì§€í•˜ë©´ì„œë„, Job Navigatorì˜ í•µì‹¬ ê¸°ëŠ¥ì¸ ì±„ìš©ê³µê³  ê´€ë¦¬ì™€ ê²€ìƒ‰ì— ì§‘ì¤‘í•©ë‹ˆë‹¤. í–¥í›„ v2ì—ì„œ í¬ë¡¤ë§ ìë™í™”ì™€ ë” ê³ ë„í™”ëœ ê¸°ëŠ¥ì„ ì¶”ê°€í•  ìˆ˜ ìˆë„ë¡ í™•ì¥ ê°€ëŠ¥í•œ êµ¬ì¡°ë¡œ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤.